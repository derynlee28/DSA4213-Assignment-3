{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, set_seed\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity(transformers.logging.CRITICAL)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# from utils import compute_metrics, run_experiment\n",
    "\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "set_seed(seed)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tK2UMjOAvk6C"
   },
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2862\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 784\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 955\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load tweet eval dataset\n",
    "\n",
    "dataset = load_dataset(\"tweet_eval\", \"irony\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Non-ironic (0): 1417 (49.5%)\n",
      "  Ironic (1): 1445 (50.5%)\n"
     ]
    }
   ],
   "source": [
    "# Class distribution\n",
    "\n",
    "train_labels = dataset['train']['label']\n",
    "print(f\"  Non-ironic (0): {train_labels.count(0)} ({train_labels.count(0)/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"  Ironic (1): {train_labels.count(1)} ({train_labels.count(1)/len(train_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GZ_EdjWvo9s"
   },
   "source": [
    "## 2. Define metrics for evaluation and experiement setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics for evaluation\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=-1)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(pred.predictions), dim=-1)[:, 1].numpy()\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds),\n",
    "        \"recall\": recall_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"binary\"),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"roc_auc\": roc_auc_score(labels, probs)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup\n",
    "\n",
    "def run_experiment(model_name, strategy, learning_rate=2e-5, batch_size=16, epochs=3, lora_config=None):\n",
    "    print(f\"\\nTraining {model_name} | {strategy} | lr={learning_rate} | batch_size={batch_size} | epochs={epochs}\")\n",
    "\n",
    "    # Initialize the tokenizer for this model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize dataset and convert to pytorch\n",
    "    tokenized_data = dataset.map(\n",
    "        lambda x: tokenizer(x['text'], padding='max_length', truncation=True, max_length=128),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized_data = tokenized_data.rename_column('label', 'labels')\n",
    "    tokenized_data.set_format('torch')\n",
    "\n",
    "    # Load models\n",
    "    if strategy == \"full\":\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    elif strategy == \"lora\":\n",
    "        base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "        # Have to determine target modules for LoRA\n",
    "        if model_name.startswith(\"distilbert\"):\n",
    "            target_modules = [\"q_lin\", \"v_lin\"]\n",
    "        elif model_name.startswith(\"roberta\"):\n",
    "            target_modules = [\"query\", \"value\"]\n",
    "        else:\n",
    "            target_modules = None\n",
    "\n",
    "        # LoRA configurations (create default ones if theres no lora_config)\n",
    "        if lora_config is None:\n",
    "            lora_config = LoraConfig(\n",
    "                task_type=TaskType.SEQ_CLS,\n",
    "                r=8,\n",
    "                lora_alpha=16,\n",
    "                lora_dropout=0.1,\n",
    "                bias=\"none\",\n",
    "                target_modules=target_modules)\n",
    "        else:\n",
    "            # If target_modules not set in the provided config, fill it\n",
    "            if getattr(lora_config, \"target_modules\", None) is None:\n",
    "                lora_config.target_modules = target_modules\n",
    "\n",
    "        model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Trainable params: {trainable_params:,}/{total_params:,}\")\n",
    "\n",
    "    # Move model to GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/{model_name}_{strategy}_lr{learning_rate}_bs{batch_size}_ep{epochs}\",\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        logging_steps=100,\n",
    "        warmup_steps=100,\n",
    "        report_to=\"none\",\n",
    "        dataloader_num_workers=0)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_data['train'],\n",
    "        eval_dataset=tokenized_data['validation'],\n",
    "        compute_metrics=compute_metrics)\n",
    "\n",
    "    # Train & evaluate + track training time\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    eval_results = trainer.evaluate(tokenized_data['test'])\n",
    "    preds = trainer.predict(tokenized_data['test'])\n",
    "    y_pred = np.argmax(preds.predictions, axis=-1)\n",
    "    y_true = preds.label_ids\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    test_texts = dataset['test']['text']\n",
    "    df_test = pd.DataFrame({\n",
    "        'text': test_texts,\n",
    "        'true_label': y_true,\n",
    "        'pred_label': y_pred\n",
    "    })\n",
    "    error_cases = df_test[df_test['true_label'] != df_test['pred_label']]\n",
    "\n",
    "    return {\n",
    "        \"mode\": model,\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"model\": model_name,\n",
    "        \"strategy\": strategy,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"train_time_s\": train_time,\n",
    "        \"accuracy\": eval_results.get('eval_accuracy'),\n",
    "        \"precision\": eval_results.get('eval_precision'),\n",
    "        \"recall\": eval_results.get('eval_recall'),\n",
    "        \"f1\": eval_results.get('eval_f1'),\n",
    "        \"f1_macro\": eval_results.get('eval_f1_macro'),\n",
    "        \"roc_auc\": eval_results.get('eval_roc_auc'),\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"error_cases\": error_cases.head(10)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qqj_ftZKvt7r"
   },
   "source": [
    "## 3. Baseline experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training distilbert-base-uncased | full | lr=2e-05 | batch_size=16 | epochs=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bfca4605c741ea9b1ea77d35774280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 66,955,010/66,955,010\n",
      "{'loss': 0.6789, 'grad_norm': 3.1427061557769775, 'learning_rate': 1.98e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.6331588625907898, 'eval_accuracy': 0.6094240837696335, 'eval_precision': 0.563165905631659, 'eval_recall': 0.8114035087719298, 'eval_f1': 0.6648697214734951, 'eval_f1_macro': 0.5984323513264589, 'eval_roc_auc': 0.7164987870477797, 'eval_runtime': 3.436, 'eval_samples_per_second': 277.941, 'eval_steps_per_second': 17.462, 'epoch': 1.0}\n",
      "{'loss': 0.6235, 'grad_norm': 4.505254745483398, 'learning_rate': 1.5469107551487414e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.5585, 'grad_norm': 6.2447190284729, 'learning_rate': 1.0892448512585814e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.5986599326133728, 'eval_accuracy': 0.6837696335078534, 'eval_precision': 0.654, 'eval_recall': 0.7171052631578947, 'eval_f1': 0.6841004184100419, 'eval_f1_macro': 0.6837692867731551, 'eval_roc_auc': 0.7531861969553142, 'eval_runtime': 3.6451, 'eval_samples_per_second': 261.998, 'eval_steps_per_second': 16.461, 'epoch': 2.0}\n",
      "{'loss': 0.4703, 'grad_norm': 5.807936191558838, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.4251, 'grad_norm': 6.189481258392334, 'learning_rate': 1.7391304347826088e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.6266939043998718, 'eval_accuracy': 0.6952879581151833, 'eval_precision': 0.6595744680851063, 'eval_recall': 0.7478070175438597, 'eval_f1': 0.7009249743062693, 'eval_f1_macro': 0.6951796696504666, 'eval_roc_auc': 0.7640104770945401, 'eval_runtime': 3.5865, 'eval_samples_per_second': 266.277, 'eval_steps_per_second': 16.729, 'epoch': 3.0}\n",
      "{'train_runtime': 131.6589, 'train_samples_per_second': 65.214, 'train_steps_per_second': 4.079, 'train_loss': 0.5417739736745255, 'epoch': 3.0}\n",
      "{'eval_loss': 0.663873553276062, 'eval_accuracy': 0.6772959183673469, 'eval_precision': 0.5732323232323232, 'eval_recall': 0.729903536977492, 'eval_f1': 0.6421499292786421, 'eval_f1_macro': 0.6741527811317717, 'eval_roc_auc': 0.747428672426803, 'eval_runtime': 2.8601, 'eval_samples_per_second': 274.121, 'eval_steps_per_second': 17.133, 'epoch': 3.0}\n",
      "\n",
      "Training distilbert-base-uncased | lora | lr=2e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 739,586/67,694,596\n",
      "{'loss': 0.6945, 'grad_norm': 1.2011430263519287, 'learning_rate': 1.98e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.6832655072212219, 'eval_accuracy': 0.5780104712041885, 'eval_precision': 0.5495327102803739, 'eval_recall': 0.6447368421052632, 'eval_f1': 0.5933400605449042, 'eval_f1_macro': 0.5774099649840951, 'eval_roc_auc': 0.6247758675245227, 'eval_runtime': 3.7681, 'eval_samples_per_second': 253.441, 'eval_steps_per_second': 15.923, 'epoch': 1.0}\n",
      "{'loss': 0.6867, 'grad_norm': 0.9007700085639954, 'learning_rate': 1.5469107551487414e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.6756, 'grad_norm': 0.9533432126045227, 'learning_rate': 1.0892448512585814e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6737337708473206, 'eval_accuracy': 0.5884816753926702, 'eval_precision': 0.5602294455066922, 'eval_recall': 0.6425438596491229, 'eval_f1': 0.5985699693564862, 'eval_f1_macro': 0.5882216119607351, 'eval_roc_auc': 0.6277511162676229, 'eval_runtime': 3.6196, 'eval_samples_per_second': 263.841, 'eval_steps_per_second': 16.576, 'epoch': 2.0}\n",
      "{'loss': 0.6689, 'grad_norm': 1.216752052307129, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.6687, 'grad_norm': 1.6671528816223145, 'learning_rate': 1.7391304347826088e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.6701759696006775, 'eval_accuracy': 0.5842931937172775, 'eval_precision': 0.5615866388308977, 'eval_recall': 0.5899122807017544, 'eval_f1': 0.5754010695187166, 'eval_f1_macro': 0.5841107911696147, 'eval_roc_auc': 0.6290212002953275, 'eval_runtime': 3.6168, 'eval_samples_per_second': 264.047, 'eval_steps_per_second': 16.589, 'epoch': 3.0}\n",
      "{'train_runtime': 75.2911, 'train_samples_per_second': 114.037, 'train_steps_per_second': 7.132, 'train_loss': 0.6774335999728581, 'epoch': 3.0}\n",
      "{'eval_loss': 0.6857383847236633, 'eval_accuracy': 0.5688775510204082, 'eval_precision': 0.4636118598382749, 'eval_recall': 0.5530546623794212, 'eval_f1': 0.5043988269794721, 'eval_f1_macro': 0.5614544924965081, 'eval_roc_auc': 0.5751276316594496, 'eval_runtime': 2.967, 'eval_samples_per_second': 264.237, 'eval_steps_per_second': 16.515, 'epoch': 3.0}\n",
      "\n",
      "Training roberta-base | full | lr=2e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'loss': 0.6869, 'grad_norm': 9.592109680175781, 'learning_rate': 1.98e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.5872989892959595, 'eval_accuracy': 0.6816753926701571, 'eval_precision': 0.6371841155234657, 'eval_recall': 0.7741228070175439, 'eval_f1': 0.699009900990099, 'eval_f1_macro': 0.6806160616061606, 'eval_roc_auc': 0.7696049994726295, 'eval_runtime': 6.2407, 'eval_samples_per_second': 153.028, 'eval_steps_per_second': 9.614, 'epoch': 1.0}\n",
      "{'loss': 0.5948, 'grad_norm': 15.75192928314209, 'learning_rate': 1.5469107551487414e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.5215, 'grad_norm': 8.389067649841309, 'learning_rate': 1.0892448512585814e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6024345755577087, 'eval_accuracy': 0.7172774869109948, 'eval_precision': 0.64576802507837, 'eval_recall': 0.9035087719298246, 'eval_f1': 0.753199268738574, 'eval_f1_macro': 0.7111584578986987, 'eval_roc_auc': 0.8306349541187638, 'eval_runtime': 6.1257, 'eval_samples_per_second': 155.9, 'eval_steps_per_second': 9.795, 'epoch': 2.0}\n",
      "{'loss': 0.4455, 'grad_norm': 13.864889144897461, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.3829, 'grad_norm': 11.901480674743652, 'learning_rate': 1.7391304347826088e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.5744064450263977, 'eval_accuracy': 0.7424083769633508, 'eval_precision': 0.6923076923076923, 'eval_recall': 0.8289473684210527, 'eval_f1': 0.7544910179640718, 'eval_f1_macro': 0.7417829539159566, 'eval_roc_auc': 0.8418767359279964, 'eval_runtime': 6.1669, 'eval_samples_per_second': 154.86, 'eval_steps_per_second': 9.729, 'epoch': 3.0}\n",
      "{'train_runtime': 258.0378, 'train_samples_per_second': 33.274, 'train_steps_per_second': 2.081, 'train_loss': 0.5144227789766962, 'epoch': 3.0}\n",
      "{'eval_loss': 0.638412356376648, 'eval_accuracy': 0.7091836734693877, 'eval_precision': 0.6169014084507042, 'eval_recall': 0.7041800643086816, 'eval_f1': 0.6576576576576577, 'eval_f1_macro': 0.7024430195161903, 'eval_roc_auc': 0.78453872456714, 'eval_runtime': 5.0129, 'eval_samples_per_second': 156.396, 'eval_steps_per_second': 9.775, 'epoch': 3.0}\n",
      "\n",
      "Training roberta-base | lora | lr=2e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 887,042/125,534,212\n",
      "{'loss': 0.6936, 'grad_norm': 1.3757697343826294, 'learning_rate': 1.98e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.6923089027404785, 'eval_accuracy': 0.543455497382199, 'eval_precision': 0.512853470437018, 'eval_recall': 0.875, 'eval_f1': 0.646677471636953, 'eval_f1_macro': 0.5008535287178848, 'eval_roc_auc': 0.5820698414372604, 'eval_runtime': 6.2858, 'eval_samples_per_second': 151.931, 'eval_steps_per_second': 9.545, 'epoch': 1.0}\n",
      "{'loss': 0.6944, 'grad_norm': 0.7290481328964233, 'learning_rate': 1.5469107551487414e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.6907, 'grad_norm': 0.866235077381134, 'learning_rate': 1.0892448512585814e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6903566718101501, 'eval_accuracy': 0.5685863874345549, 'eval_precision': 0.5315186246418339, 'eval_recall': 0.8135964912280702, 'eval_f1': 0.6429809358752167, 'eval_f1_macro': 0.5490036954508358, 'eval_roc_auc': 0.6048324719614668, 'eval_runtime': 6.3657, 'eval_samples_per_second': 150.022, 'eval_steps_per_second': 9.425, 'epoch': 2.0}\n",
      "{'loss': 0.6904, 'grad_norm': 2.443934202194214, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.6882, 'grad_norm': 2.786653995513916, 'learning_rate': 1.7391304347826088e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.6892393827438354, 'eval_accuracy': 0.5790575916230366, 'eval_precision': 0.5432692307692307, 'eval_recall': 0.743421052631579, 'eval_f1': 0.6277777777777778, 'eval_f1_macro': 0.5717202141900937, 'eval_roc_auc': 0.609161305066273, 'eval_runtime': 6.3185, 'eval_samples_per_second': 151.143, 'eval_steps_per_second': 9.496, 'epoch': 3.0}\n",
      "{'train_runtime': 145.8895, 'train_samples_per_second': 58.853, 'train_steps_per_second': 3.681, 'train_loss': 0.6910636944477785, 'epoch': 3.0}\n",
      "{'eval_loss': 0.691686749458313, 'eval_accuracy': 0.5459183673469388, 'eval_precision': 0.44630071599045346, 'eval_recall': 0.6012861736334405, 'eval_f1': 0.5123287671232877, 'eval_f1_macro': 0.5437538823683263, 'eval_roc_auc': 0.5775918913958247, 'eval_runtime': 5.2018, 'eval_samples_per_second': 150.717, 'eval_steps_per_second': 9.42, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# First, run the baseline experiments for distilbert and roberta\n",
    "\n",
    "baseline_results = []\n",
    "baseline_models = [\"distilbert-base-uncased\", \"roberta-base\"]\n",
    "\n",
    "for model_name in baseline_models:\n",
    "    for strategy in [\"full\", \"lora\"]:\n",
    "        lora_cfg = None\n",
    "        if strategy == \"lora\":\n",
    "            lora_cfg = LoraConfig(task_type=TaskType.SEQ_CLS, r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\")\n",
    "        result = run_experiment(model_name, strategy, learning_rate=2e-5, batch_size=16, epochs=3, lora_config=lora_cfg)\n",
    "        baseline_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_baseline_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"PeftModelForSequenceClassification(\\n  (base_model): LoraModel(\\n    (model): DistilBertForSequenceClassification(\\n      (distilbert): DistilBertModel(\\n        (embeddings): Embeddings(\\n          (word_embeddings): Embedding(30522, 768, padding_idx=0)\\n          (position_embeddings): Embedding(512, 768)\\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          (dropout): Dropout(p=0.1, inplace=False)\\n        )\\n        (transformer): Transformer(\\n          (layer): ModuleList(\\n            (0-5): 6 x TransformerBlock(\\n              (attention): DistilBertSdpaAttention(\\n                (dropout): Dropout(p=0.1, inplace=False)\\n                (q_lin): lora.Linear(\\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\\n                  (lora_dropout): ModuleDict(\\n                    (default): Dropout(p=0.1, inplace=False)\\n                  )\\n                  (lora_A): ModuleDict(\\n                    (default): Linear(in_features=768, out_features=8, bias=False)\\n                  )\\n                  (lora_B): ModuleDict(\\n                    (default): Linear(in_features=8, out_features=768, bias=False)\\n                  )\\n                  (lora_embedding_A): ParameterDict()\\n                  (lora_embedding_B): ParameterDict()\\n                  (lora_magnitude_vector): ModuleDict()\\n                )\\n                (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n                (v_lin): lora.Linear(\\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\\n                  (lora_dropout): ModuleDict(\\n                    (default): Dropout(p=0.1, inplace=False)\\n                  )\\n                  (lora_A): ModuleDict(\\n                    (default): Linear(in_features=768, out_features=8, bias=False)\\n                  )\\n                  (lora_B): ModuleDict(\\n                    (default): Linear(in_features=8, out_features=768, bias=False)\\n                  )\\n                  (lora_embedding_A): ParameterDict()\\n                  (lora_embedding_B): ParameterDict()\\n                  (lora_magnitude_vector): ModuleDict()\\n                )\\n                (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n              )\\n              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n              (ffn): FFN(\\n                (dropout): Dropout(p=0.1, inplace=False)\\n                (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n                (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n                (activation): GELUActivation()\\n              )\\n              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n            )\\n          )\\n        )\\n      )\\n      (pre_classifier): ModulesToSaveWrapper(\\n        (original_module): Linear(in_features=768, out_features=768, bias=True)\\n        (modules_to_save): ModuleDict(\\n          (default): Linear(in_features=768, out_features=768, bias=True)\\n        )\\n      )\\n      (classifier): ModulesToSaveWrapper(\\n        (original_module): Linear(in_features=768, out_features=2, bias=True)\\n        (modules_to_save): ModuleDict(\\n          (default): Linear(in_features=768, out_features=2, bias=True)\\n        )\\n      )\\n      (dropout): Dropout(p=0.2, inplace=False)\\n    )\\n  )\\n)\",\n          \"PeftModelForSequenceClassification(\\n  (base_model): LoraModel(\\n    (model): RobertaForSequenceClassification(\\n      (roberta): RobertaModel(\\n        (embeddings): RobertaEmbeddings(\\n          (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n          (position_embeddings): Embedding(514, 768, padding_idx=1)\\n          (token_type_embeddings): Embedding(1, 768)\\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n          (dropout): Dropout(p=0.1, inplace=False)\\n        )\\n        (encoder): RobertaEncoder(\\n          (layer): ModuleList(\\n            (0-11): 12 x RobertaLayer(\\n              (attention): RobertaAttention(\\n                (self): RobertaSdpaSelfAttention(\\n                  (query): lora.Linear(\\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\\n                    (lora_dropout): ModuleDict(\\n                      (default): Dropout(p=0.1, inplace=False)\\n                    )\\n                    (lora_A): ModuleDict(\\n                      (default): Linear(in_features=768, out_features=8, bias=False)\\n                    )\\n                    (lora_B): ModuleDict(\\n                      (default): Linear(in_features=8, out_features=768, bias=False)\\n                    )\\n                    (lora_embedding_A): ParameterDict()\\n                    (lora_embedding_B): ParameterDict()\\n                    (lora_magnitude_vector): ModuleDict()\\n                  )\\n                  (key): Linear(in_features=768, out_features=768, bias=True)\\n                  (value): lora.Linear(\\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\\n                    (lora_dropout): ModuleDict(\\n                      (default): Dropout(p=0.1, inplace=False)\\n                    )\\n                    (lora_A): ModuleDict(\\n                      (default): Linear(in_features=768, out_features=8, bias=False)\\n                    )\\n                    (lora_B): ModuleDict(\\n                      (default): Linear(in_features=8, out_features=768, bias=False)\\n                    )\\n                    (lora_embedding_A): ParameterDict()\\n                    (lora_embedding_B): ParameterDict()\\n                    (lora_magnitude_vector): ModuleDict()\\n                  )\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n                (output): RobertaSelfOutput(\\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\\n                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n                  (dropout): Dropout(p=0.1, inplace=False)\\n                )\\n              )\\n              (intermediate): RobertaIntermediate(\\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\\n                (intermediate_act_fn): GELUActivation()\\n              )\\n              (output): RobertaOutput(\\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n                (dropout): Dropout(p=0.1, inplace=False)\\n              )\\n            )\\n          )\\n        )\\n      )\\n      (classifier): ModulesToSaveWrapper(\\n        (original_module): RobertaClassificationHead(\\n          (dense): Linear(in_features=768, out_features=768, bias=True)\\n          (dropout): Dropout(p=0.1, inplace=False)\\n          (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n        )\\n        (modules_to_save): ModuleDict(\\n          (default): RobertaClassificationHead(\\n            (dense): Linear(in_features=768, out_features=768, bias=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n            (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n          )\\n        )\\n      )\\n    )\\n  )\\n)\",\n          \"DistilBertForSequenceClassification(\\n  (distilbert): DistilBertModel(\\n    (embeddings): Embeddings(\\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\\n      (position_embeddings): Embedding(512, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (transformer): Transformer(\\n      (layer): ModuleList(\\n        (0-5): 6 x TransformerBlock(\\n          (attention): DistilBertSdpaAttention(\\n            (dropout): Dropout(p=0.1, inplace=False)\\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\\n          )\\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n          (ffn): FFN(\\n            (dropout): Dropout(p=0.1, inplace=False)\\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\\n            (activation): GELUActivation()\\n          )\\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\\n        )\\n      )\\n    )\\n  )\\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\\n  (dropout): Dropout(p=0.2, inplace=False)\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"[PAD]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t100: AddedToken(\\\"[UNK]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t101: AddedToken(\\\"[CLS]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t102: AddedToken(\\\"[SEP]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t103: AddedToken(\\\"[MASK]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"[PAD]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t100: AddedToken(\\\"[UNK]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t101: AddedToken(\\\"[CLS]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t102: AddedToken(\\\"[SEP]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n\\t103: AddedToken(\\\"[MASK]\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\\n}\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"roberta-base\",\n          \"distilbert-base-uncased\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"lora\",\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 2e-05,\n        \"max\": 2e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 16,\n        \"max\": 16,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.4685367855638,\n        \"min\": 75.67352104187012,\n        \"max\": 258.4002492427826,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          75.67352104187012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08005202709832969,\n        \"min\": 0.5459183673469388,\n        \"max\": 0.7091836734693877,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5688775510204082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08313504355293447,\n        \"min\": 0.44630071599045346,\n        \"max\": 0.6169014084507042,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4636118598382749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08378144492802812,\n        \"min\": 0.5530546623794212,\n        \"max\": 0.729903536977492,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5530546623794212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08202694146994262,\n        \"min\": 0.5043988269794721,\n        \"max\": 0.6576576576576577,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5043988269794721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07951856871548241,\n        \"min\": 0.5437538823683263,\n        \"max\": 0.7024430195161903,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5614544924965081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11052729941015105,\n        \"min\": 0.5751276316594496,\n        \"max\": 0.78453872456714,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5751276316594496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error_cases\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_baseline_results"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-657f2018-72b3-494f-a136-60aaffdf46c7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>error_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBertForSequenceClassification(\\n  (disti...</td>\n",
       "      <td>DistilBertTokenizerFast(name_or_path='distilbe...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>132.775394</td>\n",
       "      <td>0.677296</td>\n",
       "      <td>0.573232</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.642150</td>\n",
       "      <td>0.674153</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>[[304, 169], [84, 227]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PeftModelForSequenceClassification(\\n  (base_m...</td>\n",
       "      <td>DistilBertTokenizerFast(name_or_path='distilbe...</td>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>75.673521</td>\n",
       "      <td>0.568878</td>\n",
       "      <td>0.463612</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.504399</td>\n",
       "      <td>0.561454</td>\n",
       "      <td>0.575128</td>\n",
       "      <td>[[274, 199], [139, 172]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>258.400249</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PeftModelForSequenceClassification(\\n  (base_m...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>lora</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>146.291421</td>\n",
       "      <td>0.545918</td>\n",
       "      <td>0.446301</td>\n",
       "      <td>0.601286</td>\n",
       "      <td>0.512329</td>\n",
       "      <td>0.543754</td>\n",
       "      <td>0.577592</td>\n",
       "      <td>[[241, 232], [124, 187]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657f2018-72b3-494f-a136-60aaffdf46c7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-657f2018-72b3-494f-a136-60aaffdf46c7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-657f2018-72b3-494f-a136-60aaffdf46c7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-865a485e-1cae-4d23-a441-24ccb88f219b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-865a485e-1cae-4d23-a441-24ccb88f219b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-865a485e-1cae-4d23-a441-24ccb88f219b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_cbe0d397-d3e6-466f-aa86-be96d9101d83\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_baseline_results')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_cbe0d397-d3e6-466f-aa86-be96d9101d83 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_baseline_results');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                mode  \\\n",
       "0  DistilBertForSequenceClassification(\\n  (disti...   \n",
       "1  PeftModelForSequenceClassification(\\n  (base_m...   \n",
       "2  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "3  PeftModelForSequenceClassification(\\n  (base_m...   \n",
       "\n",
       "                                           tokenizer                    model  \\\n",
       "0  DistilBertTokenizerFast(name_or_path='distilbe...  distilbert-base-uncased   \n",
       "1  DistilBertTokenizerFast(name_or_path='distilbe...  distilbert-base-uncased   \n",
       "2  RobertaTokenizerFast(name_or_path='roberta-bas...             roberta-base   \n",
       "3  RobertaTokenizerFast(name_or_path='roberta-bas...             roberta-base   \n",
       "\n",
       "  strategy  learning_rate  batch_size  epochs  train_time_s  accuracy  \\\n",
       "0     full        0.00002          16       3    132.775394  0.677296   \n",
       "1     lora        0.00002          16       3     75.673521  0.568878   \n",
       "2     full        0.00002          16       3    258.400249  0.709184   \n",
       "3     lora        0.00002          16       3    146.291421  0.545918   \n",
       "\n",
       "   precision    recall        f1  f1_macro   roc_auc  \\\n",
       "0   0.573232  0.729904  0.642150  0.674153  0.747429   \n",
       "1   0.463612  0.553055  0.504399  0.561454  0.575128   \n",
       "2   0.616901  0.704180  0.657658  0.702443  0.784539   \n",
       "3   0.446301  0.601286  0.512329  0.543754  0.577592   \n",
       "\n",
       "           confusion_matrix                                        error_cases  \n",
       "0   [[304, 169], [84, 227]]                                                ...  \n",
       "1  [[274, 199], [139, 172]]                                                ...  \n",
       "2   [[337, 136], [92, 219]]                                                ...  \n",
       "3  [[241, 232], [124, 187]]                                                ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_results = pd.DataFrame(baseline_results)\n",
    "df_baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_baseline\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"distilbert-base-uncased\",\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"lora\",\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.4685367855638,\n        \"min\": 75.67352104187012,\n        \"max\": 258.4002492427826,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          132.77539443969727,\n          146.29142117500305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08005202709832969,\n        \"min\": 0.5459183673469388,\n        \"max\": 0.7091836734693877,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6772959183673469,\n          0.5459183673469388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08202694146994262,\n        \"min\": 0.5043988269794721,\n        \"max\": 0.6576576576576577,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6421499292786421,\n          0.5123287671232877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07951856871548241,\n        \"min\": 0.5437538823683263,\n        \"max\": 0.7024430195161903,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6741527811317717,\n          0.5437538823683263\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11052729941015105,\n        \"min\": 0.5751276316594496,\n        \"max\": 0.78453872456714,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.747428672426803,\n          0.5775918913958247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_baseline"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-7b248516-e0f8-4f3a-995f-c4aaf730247d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>258.400249</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>full</td>\n",
       "      <td>132.775394</td>\n",
       "      <td>0.677296</td>\n",
       "      <td>0.642150</td>\n",
       "      <td>0.674153</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>[[304, 169], [84, 227]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>lora</td>\n",
       "      <td>75.673521</td>\n",
       "      <td>0.568878</td>\n",
       "      <td>0.504399</td>\n",
       "      <td>0.561454</td>\n",
       "      <td>0.575128</td>\n",
       "      <td>[[274, 199], [139, 172]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>lora</td>\n",
       "      <td>146.291421</td>\n",
       "      <td>0.545918</td>\n",
       "      <td>0.512329</td>\n",
       "      <td>0.543754</td>\n",
       "      <td>0.577592</td>\n",
       "      <td>[[241, 232], [124, 187]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b248516-e0f8-4f3a-995f-c4aaf730247d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7b248516-e0f8-4f3a-995f-c4aaf730247d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7b248516-e0f8-4f3a-995f-c4aaf730247d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-eadb5307-e013-46a1-bb14-5b353f23b662\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eadb5307-e013-46a1-bb14-5b353f23b662')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-eadb5307-e013-46a1-bb14-5b353f23b662 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_55379cb7-a75a-47ad-a125-f731db5a436b\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_baseline')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_55379cb7-a75a-47ad-a125-f731db5a436b button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_baseline');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                     model strategy  train_time_s  accuracy        f1  \\\n",
       "2             roberta-base     full    258.400249  0.709184  0.657658   \n",
       "0  distilbert-base-uncased     full    132.775394  0.677296  0.642150   \n",
       "1  distilbert-base-uncased     lora     75.673521  0.568878  0.504399   \n",
       "3             roberta-base     lora    146.291421  0.545918  0.512329   \n",
       "\n",
       "   f1_macro   roc_auc          confusion_matrix  \n",
       "2  0.702443  0.784539   [[337, 136], [92, 219]]  \n",
       "0  0.674153  0.747429   [[304, 169], [84, 227]]  \n",
       "1  0.561454  0.575128  [[274, 199], [139, 172]]  \n",
       "3  0.543754  0.577592  [[241, 232], [124, 187]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = (df_baseline_results.drop([\"mode\", \"tokenizer\", \"precision\", \"recall\", \"learning_rate\", \"batch_size\", \"epochs\", \"error_cases\"], axis=1)\n",
    "    .sort_values(\"f1_macro\", ascending=False))\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wti2mheUvxEt"
   },
   "source": [
    "## 4. RoBERTa experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full fine-tuning\n",
      "FULL: lr=2e-05, bs=16, epochs=3\n",
      "\n",
      "Training roberta-base | full | lr=2e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'loss': 0.6869, 'grad_norm': 9.592109680175781, 'learning_rate': 1.98e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.5872989892959595, 'eval_accuracy': 0.6816753926701571, 'eval_precision': 0.6371841155234657, 'eval_recall': 0.7741228070175439, 'eval_f1': 0.699009900990099, 'eval_f1_macro': 0.6806160616061606, 'eval_roc_auc': 0.7696049994726295, 'eval_runtime': 6.2343, 'eval_samples_per_second': 153.184, 'eval_steps_per_second': 9.624, 'epoch': 1.0}\n",
      "{'loss': 0.5948, 'grad_norm': 15.75192928314209, 'learning_rate': 1.5469107551487414e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.5215, 'grad_norm': 8.389067649841309, 'learning_rate': 1.0892448512585814e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6024345755577087, 'eval_accuracy': 0.7172774869109948, 'eval_precision': 0.64576802507837, 'eval_recall': 0.9035087719298246, 'eval_f1': 0.753199268738574, 'eval_f1_macro': 0.7111584578986987, 'eval_roc_auc': 0.8306349541187638, 'eval_runtime': 6.0759, 'eval_samples_per_second': 157.179, 'eval_steps_per_second': 9.875, 'epoch': 2.0}\n",
      "{'loss': 0.4455, 'grad_norm': 13.864889144897461, 'learning_rate': 6.31578947368421e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.3829, 'grad_norm': 11.901480674743652, 'learning_rate': 1.7391304347826088e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.5744064450263977, 'eval_accuracy': 0.7424083769633508, 'eval_precision': 0.6923076923076923, 'eval_recall': 0.8289473684210527, 'eval_f1': 0.7544910179640718, 'eval_f1_macro': 0.7417829539159566, 'eval_roc_auc': 0.8418767359279964, 'eval_runtime': 6.1661, 'eval_samples_per_second': 154.878, 'eval_steps_per_second': 9.731, 'epoch': 3.0}\n",
      "{'train_runtime': 331.3675, 'train_samples_per_second': 25.911, 'train_steps_per_second': 1.621, 'train_loss': 0.5144227789766962, 'epoch': 3.0}\n",
      "{'eval_loss': 0.638412356376648, 'eval_accuracy': 0.7091836734693877, 'eval_precision': 0.6169014084507042, 'eval_recall': 0.7041800643086816, 'eval_f1': 0.6576576576576577, 'eval_f1_macro': 0.7024430195161903, 'eval_roc_auc': 0.78453872456714, 'eval_runtime': 5.0746, 'eval_samples_per_second': 154.494, 'eval_steps_per_second': 9.656, 'epoch': 3.0}\n",
      "FULL: lr=3e-05, bs=16, epochs=3\n",
      "\n",
      "Training roberta-base | full | lr=3e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'loss': 0.6834, 'grad_norm': 9.523895263671875, 'learning_rate': 2.97e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.5891972184181213, 'eval_accuracy': 0.6785340314136126, 'eval_precision': 0.6323268206039077, 'eval_recall': 0.7807017543859649, 'eval_f1': 0.6987242394504416, 'eval_f1_macro': 0.6770837807802152, 'eval_roc_auc': 0.7769002918116935, 'eval_runtime': 6.1387, 'eval_samples_per_second': 155.571, 'eval_steps_per_second': 9.774, 'epoch': 1.0}\n",
      "{'loss': 0.5936, 'grad_norm': 17.550241470336914, 'learning_rate': 2.320366132723112e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.4965, 'grad_norm': 11.382208824157715, 'learning_rate': 1.6338672768878718e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6055995225906372, 'eval_accuracy': 0.7015706806282722, 'eval_precision': 0.6329704510108864, 'eval_recall': 0.8925438596491229, 'eval_f1': 0.740673339399454, 'eval_f1_macro': 0.6946276684666814, 'eval_roc_auc': 0.8351791301902048, 'eval_runtime': 6.1204, 'eval_samples_per_second': 156.035, 'eval_steps_per_second': 9.803, 'epoch': 2.0}\n",
      "{'loss': 0.4288, 'grad_norm': 14.587890625, 'learning_rate': 9.473684210526315e-06, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.3366, 'grad_norm': 19.54667091369629, 'learning_rate': 2.6086956521739132e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.5817673206329346, 'eval_accuracy': 0.7591623036649214, 'eval_precision': 0.7132075471698113, 'eval_recall': 0.8289473684210527, 'eval_f1': 0.7667342799188641, 'eval_f1_macro': 0.7589082655005577, 'eval_roc_auc': 0.8500246106247583, 'eval_runtime': 6.1616, 'eval_samples_per_second': 154.991, 'eval_steps_per_second': 9.738, 'epoch': 3.0}\n",
      "{'train_runtime': 267.6472, 'train_samples_per_second': 32.08, 'train_steps_per_second': 2.006, 'train_loss': 0.4929059470832015, 'epoch': 3.0}\n",
      "{'eval_loss': 0.6816958785057068, 'eval_accuracy': 0.7053571428571429, 'eval_precision': 0.6092896174863388, 'eval_recall': 0.7170418006430869, 'eval_f1': 0.6587887740029542, 'eval_f1_macro': 0.6997647573718475, 'eval_roc_auc': 0.7748244427374016, 'eval_runtime': 5.0218, 'eval_samples_per_second': 156.121, 'eval_steps_per_second': 9.758, 'epoch': 3.0}\n",
      "FULL: lr=4e-05, bs=16, epochs=3\n",
      "\n",
      "Training roberta-base | full | lr=4e-05 | batch_size=16 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'loss': 0.6772, 'grad_norm': 7.203981399536133, 'learning_rate': 3.96e-05, 'epoch': 0.5586592178770949}\n",
      "{'eval_loss': 0.610679030418396, 'eval_accuracy': 0.6712041884816754, 'eval_precision': 0.663594470046083, 'eval_recall': 0.631578947368421, 'eval_f1': 0.647191011235955, 'eval_f1_macro': 0.6696739369905265, 'eval_roc_auc': 0.7290106528847168, 'eval_runtime': 6.1271, 'eval_samples_per_second': 155.864, 'eval_steps_per_second': 9.793, 'epoch': 1.0}\n",
      "{'loss': 0.6105, 'grad_norm': 24.821401596069336, 'learning_rate': 3.093821510297483e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.5224, 'grad_norm': 14.075518608093262, 'learning_rate': 2.1784897025171628e-05, 'epoch': 1.675977653631285}\n",
      "{'eval_loss': 0.6074422001838684, 'eval_accuracy': 0.7130890052356021, 'eval_precision': 0.6526845637583892, 'eval_recall': 0.8530701754385965, 'eval_f1': 0.7395437262357415, 'eval_f1_macro': 0.7100982034442112, 'eval_roc_auc': 0.8176001125057133, 'eval_runtime': 6.111, 'eval_samples_per_second': 156.277, 'eval_steps_per_second': 9.818, 'epoch': 2.0}\n",
      "{'loss': 0.4397, 'grad_norm': 21.081220626831055, 'learning_rate': 1.263157894736842e-05, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.3589, 'grad_norm': 11.478876113891602, 'learning_rate': 3.4782608695652175e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.5710271596908569, 'eval_accuracy': 0.7549738219895288, 'eval_precision': 0.7134615384615385, 'eval_recall': 0.8135964912280702, 'eval_f1': 0.7602459016393442, 'eval_f1_macro': 0.7548552848667813, 'eval_roc_auc': 0.8463945434729108, 'eval_runtime': 6.1174, 'eval_samples_per_second': 156.111, 'eval_steps_per_second': 9.808, 'epoch': 3.0}\n",
      "{'train_runtime': 294.5334, 'train_samples_per_second': 29.151, 'train_steps_per_second': 1.823, 'train_loss': 0.5071744315007102, 'epoch': 3.0}\n",
      "{'eval_loss': 0.6860873699188232, 'eval_accuracy': 0.7130102040816326, 'eval_precision': 0.6174863387978142, 'eval_recall': 0.7266881028938906, 'eval_f1': 0.6676514032496307, 'eval_f1_macro': 0.7075630753621891, 'eval_roc_auc': 0.7813096945677519, 'eval_runtime': 5.0365, 'eval_samples_per_second': 155.663, 'eval_steps_per_second': 9.729, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Run RobERTA\n",
    "\n",
    "roberta_results = []\n",
    "\n",
    "# Baseline\n",
    "baseline_lr = 2e-5\n",
    "baseline_full_bs = 16\n",
    "baseline_lora_bs = 16\n",
    "baseline_epochs = 3\n",
    "baseline_lora_dropout = 0.1\n",
    "\n",
    "# Hyperparameters to tune\n",
    "\n",
    "learning_rates = [2e-5, 3e-5, 4e-5]\n",
    "full_batch_sizes = [8, 16, 32]\n",
    "lora_batch_sizes = [8, 16]\n",
    "epochs_list = [3, 4]\n",
    "lora_dropouts = [0.05, 0.1]\n",
    "\n",
    "# For fine-tuning, vary fine-tuning one factor at a time first\n",
    "# For full fine-tuning\n",
    "print(\"Full fine-tuning\")\n",
    "\n",
    "# 1. Learning rate\n",
    "for lr in learning_rates:\n",
    "    print(f\"FULL: lr={lr}, bs={baseline_full_bs}, epochs={baseline_epochs}\")\n",
    "    result = run_experiment(\n",
    "        model_name=\"roberta-base\",\n",
    "        strategy=\"full\",\n",
    "        learning_rate=lr,\n",
    "        batch_size=baseline_full_bs,\n",
    "        epochs=baseline_epochs,\n",
    "        lora_config=None\n",
    "    )\n",
    "    roberta_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_roberta_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1e-05,\n        \"min\": 2e-05,\n        \"max\": 4e-05,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 16,\n        \"max\": 16,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.01780452039567,\n        \"min\": 268.09077644348145,\n        \"max\": 331.86491894721985,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          331.86491894721985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0038265306122448606,\n        \"min\": 0.7053571428571429,\n        \"max\": 0.7130102040816326,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7091836734693877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004572886496407564,\n        \"min\": 0.6092896174863388,\n        \"max\": 0.6174863387978142,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6169014084507042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011292233389981502,\n        \"min\": 0.7041800643086816,\n        \"max\": 0.7266881028938906,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7041800643086816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005472668031647835,\n        \"min\": 0.6576576576576577,\n        \"max\": 0.6676514032496307,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6576576576576577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003962360900996011,\n        \"min\": 0.6997647573718475,\n        \"max\": 0.7075630753621891,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7024430195161903\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004947261826970499,\n        \"min\": 0.7748244427374016,\n        \"max\": 0.78453872456714,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.78453872456714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error_cases\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_roberta_results"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-25cc0b2c-f2f0-4ef2-b94f-72ff0c6551fa\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>error_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>331.864919</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>268.090776</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.609290</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.774824</td>\n",
       "      <td>[[330, 143], [88, 223]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>294.971504</td>\n",
       "      <td>0.713010</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.667651</td>\n",
       "      <td>0.707563</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>[[333, 140], [85, 226]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25cc0b2c-f2f0-4ef2-b94f-72ff0c6551fa')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-25cc0b2c-f2f0-4ef2-b94f-72ff0c6551fa button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-25cc0b2c-f2f0-4ef2-b94f-72ff0c6551fa');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-fe15ec2e-58d1-411e-ac14-05e7a430502f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe15ec2e-58d1-411e-ac14-05e7a430502f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-fe15ec2e-58d1-411e-ac14-05e7a430502f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_542a5685-ff13-4493-8763-1e4612129660\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_roberta_results')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_542a5685-ff13-4493-8763-1e4612129660 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_roberta_results');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                mode  \\\n",
       "0  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "1  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "2  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "\n",
       "                                           tokenizer         model strategy  \\\n",
       "0  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "1  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "2  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "\n",
       "   learning_rate  batch_size  epochs  train_time_s  accuracy  precision  \\\n",
       "0        0.00002          16       3    331.864919  0.709184   0.616901   \n",
       "1        0.00003          16       3    268.090776  0.705357   0.609290   \n",
       "2        0.00004          16       3    294.971504  0.713010   0.617486   \n",
       "\n",
       "     recall        f1  f1_macro   roc_auc         confusion_matrix  \\\n",
       "0  0.704180  0.657658  0.702443  0.784539  [[337, 136], [92, 219]]   \n",
       "1  0.717042  0.658789  0.699765  0.774824  [[330, 143], [88, 223]]   \n",
       "2  0.726688  0.667651  0.707563  0.781310  [[333, 140], [85, 226]]   \n",
       "\n",
       "                                         error_cases  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roberta_results = pd.DataFrame(roberta_results)\n",
    "df_roberta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL: lr=4e-05, bs=8, epochs=3\n",
      "\n",
      "Training roberta-base | full | lr=4e-05 | batch_size=8 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'loss': 0.6853, 'grad_norm': 7.8745622634887695, 'learning_rate': 3.96e-05, 'epoch': 0.27932960893854747}\n",
      "{'loss': 0.651, 'grad_norm': 9.635052680969238, 'learning_rate': 3.593429158110883e-05, 'epoch': 0.5586592178770949}\n",
      "{'loss': 0.6519, 'grad_norm': 3.712763786315918, 'learning_rate': 3.182751540041068e-05, 'epoch': 0.8379888268156425}\n",
      "{'eval_loss': 0.6150221228599548, 'eval_accuracy': 0.6732984293193718, 'eval_precision': 0.6157556270096463, 'eval_recall': 0.8399122807017544, 'eval_f1': 0.7105751391465677, 'eval_f1_macro': 0.6677875695732838, 'eval_roc_auc': 0.7951692859403017, 'eval_runtime': 6.2539, 'eval_samples_per_second': 152.704, 'eval_steps_per_second': 19.188, 'epoch': 1.0}\n",
      "{'loss': 0.5485, 'grad_norm': 39.85838317871094, 'learning_rate': 2.7720739219712527e-05, 'epoch': 1.1173184357541899}\n",
      "{'loss': 0.4963, 'grad_norm': 24.21317481994629, 'learning_rate': 2.3613963039014375e-05, 'epoch': 1.3966480446927374}\n",
      "{'loss': 0.4883, 'grad_norm': 35.430240631103516, 'learning_rate': 1.9507186858316223e-05, 'epoch': 1.675977653631285}\n",
      "{'loss': 0.45, 'grad_norm': 7.22774076461792, 'learning_rate': 1.540041067761807e-05, 'epoch': 1.9553072625698324}\n",
      "{'eval_loss': 0.5622512698173523, 'eval_accuracy': 0.7476439790575916, 'eval_precision': 0.7311827956989247, 'eval_recall': 0.7456140350877193, 'eval_f1': 0.738327904451683, 'eval_f1_macro': 0.7473237095564784, 'eval_roc_auc': 0.8297208451991702, 'eval_runtime': 6.2352, 'eval_samples_per_second': 153.162, 'eval_steps_per_second': 19.245, 'epoch': 2.0}\n",
      "{'loss': 0.3417, 'grad_norm': 12.955242156982422, 'learning_rate': 1.1293634496919918e-05, 'epoch': 2.2346368715083798}\n",
      "{'loss': 0.2897, 'grad_norm': 24.162399291992188, 'learning_rate': 7.1868583162217665e-06, 'epoch': 2.5139664804469275}\n",
      "{'loss': 0.3121, 'grad_norm': 34.3590202331543, 'learning_rate': 3.0800821355236142e-06, 'epoch': 2.793296089385475}\n",
      "{'eval_loss': 0.8013596534729004, 'eval_accuracy': 0.7455497382198953, 'eval_precision': 0.7020872865275142, 'eval_recall': 0.8114035087719298, 'eval_f1': 0.7527975584944049, 'eval_f1_macro': 0.7453308180821538, 'eval_roc_auc': 0.8465263861055444, 'eval_runtime': 6.2286, 'eval_samples_per_second': 153.326, 'eval_steps_per_second': 19.266, 'epoch': 3.0}\n",
      "{'train_runtime': 324.3229, 'train_samples_per_second': 26.474, 'train_steps_per_second': 3.312, 'train_loss': 0.4752273115587856, 'epoch': 3.0}\n",
      "{'eval_loss': 0.7740456461906433, 'eval_accuracy': 0.6836734693877551, 'eval_precision': 0.6235294117647059, 'eval_recall': 0.5112540192926045, 'eval_f1': 0.5618374558303887, 'eval_f1_macro': 0.6571662329052144, 'eval_roc_auc': 0.7200600939477781, 'eval_runtime': 5.1841, 'eval_samples_per_second': 151.23, 'eval_steps_per_second': 18.904, 'epoch': 3.0}\n",
      "FULL: lr=4e-05, bs=32, epochs=3\n",
      "\n",
      "Training roberta-base | full | lr=4e-05 | batch_size=32 | epochs=3\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'eval_loss': 0.5962445735931396, 'eval_accuracy': 0.6984293193717277, 'eval_precision': 0.7028985507246377, 'eval_recall': 0.6381578947368421, 'eval_f1': 0.6689655172413793, 'eval_f1_macro': 0.6960212201591511, 'eval_roc_auc': 0.7657551945997257, 'eval_runtime': 5.6512, 'eval_samples_per_second': 168.99, 'eval_steps_per_second': 5.309, 'epoch': 1.0}\n",
      "{'loss': 0.6524, 'grad_norm': 17.647567749023438, 'learning_rate': 3.96e-05, 'epoch': 1.1111111111111112}\n",
      "{'eval_loss': 0.5547864437103271, 'eval_accuracy': 0.7225130890052356, 'eval_precision': 0.6523125996810207, 'eval_recall': 0.8969298245614035, 'eval_f1': 0.7553093259464451, 'eval_f1_macro': 0.7174370088015176, 'eval_roc_auc': 0.8425798966353759, 'eval_runtime': 5.676, 'eval_samples_per_second': 168.252, 'eval_steps_per_second': 5.285, 'epoch': 2.0}\n",
      "{'loss': 0.4872, 'grad_norm': 13.031961441040039, 'learning_rate': 1.670588235294118e-05, 'epoch': 2.2222222222222223}\n",
      "{'eval_loss': 0.5437241792678833, 'eval_accuracy': 0.7549738219895288, 'eval_precision': 0.7151162790697675, 'eval_recall': 0.8092105263157895, 'eval_f1': 0.7592592592592593, 'eval_f1_macro': 0.7548961541498855, 'eval_roc_auc': 0.8522483563618466, 'eval_runtime': 5.6923, 'eval_samples_per_second': 167.77, 'eval_steps_per_second': 5.27, 'epoch': 3.0}\n",
      "{'train_runtime': 262.7323, 'train_samples_per_second': 32.68, 'train_steps_per_second': 1.028, 'train_loss': 0.5051829090824833, 'epoch': 3.0}\n",
      "{'eval_loss': 0.6127833127975464, 'eval_accuracy': 0.7244897959183674, 'eval_precision': 0.6323119777158774, 'eval_recall': 0.729903536977492, 'eval_f1': 0.6776119402985075, 'eval_f1_macro': 0.7185387095701892, 'eval_roc_auc': 0.8039468943529364, 'eval_runtime': 4.6374, 'eval_samples_per_second': 169.06, 'eval_steps_per_second': 5.391, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# 2. Batch size (use best LR from previous step manually)\n",
    "best_lr_full = 4e-5\n",
    "full_batch_sizes = [8, 32] # Already have for batch size 16\n",
    "\n",
    "for bs in full_batch_sizes:\n",
    "    print(f\"FULL: lr={best_lr_full}, bs={bs}, epochs={baseline_epochs}\")\n",
    "    result = run_experiment(\n",
    "        model_name=\"roberta-base\",\n",
    "        strategy=\"full\",\n",
    "        learning_rate=best_lr_full,\n",
    "        batch_size=bs,\n",
    "        epochs=baseline_epochs,\n",
    "        lora_config=None\n",
    "    )\n",
    "    roberta_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_roberta_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.94427190999916e-06,\n        \"min\": 2e-05,\n        \"max\": 4e-05,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 8,\n        \"max\": 32,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.50275658914609,\n        \"min\": 263.18537735939026,\n        \"max\": 331.86491894721985,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          268.09077644348145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014945801361665343,\n        \"min\": 0.6836734693877551,\n        \"max\": 0.7244897959183674,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7053571428571429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008582355140020667,\n        \"min\": 0.6092896174863388,\n        \"max\": 0.6323119777158774,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6092896174863388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09364589507642257,\n        \"min\": 0.5112540192926045,\n        \"max\": 0.729903536977492,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7170418006430869\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04701743812226913,\n        \"min\": 0.5618374558303887,\n        \"max\": 0.6776119402985075,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6587887740029542\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02344913985987811,\n        \"min\": 0.6571662329052144,\n        \"max\": 0.7185387095701892,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6997647573718475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03148747847746483,\n        \"min\": 0.7200600939477781,\n        \"max\": 0.8039468943529364,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7748244427374016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error_cases\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_roberta_results"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5477f135-d243-4864-8f55-0e1e3bcaee82\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>error_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>331.864919</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>268.090776</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.609290</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.774824</td>\n",
       "      <td>[[330, 143], [88, 223]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>294.971504</td>\n",
       "      <td>0.713010</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.667651</td>\n",
       "      <td>0.707563</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>[[333, 140], [85, 226]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>324.780093</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.511254</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.657166</td>\n",
       "      <td>0.720060</td>\n",
       "      <td>[[377, 96], [152, 159]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>263.185377</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.677612</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>[[341, 132], [84, 227]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5477f135-d243-4864-8f55-0e1e3bcaee82')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5477f135-d243-4864-8f55-0e1e3bcaee82 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5477f135-d243-4864-8f55-0e1e3bcaee82');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-0d987a82-16a2-4c71-ae52-32d94ca38c88\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d987a82-16a2-4c71-ae52-32d94ca38c88')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-0d987a82-16a2-4c71-ae52-32d94ca38c88 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_8b325b30-7ac6-4087-9ab1-a8d95e6d5c51\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_roberta_results')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_8b325b30-7ac6-4087-9ab1-a8d95e6d5c51 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_roberta_results');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                mode  \\\n",
       "0  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "1  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "2  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "3  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "4  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "\n",
       "                                           tokenizer         model strategy  \\\n",
       "0  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "1  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "2  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "3  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "4  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "\n",
       "   learning_rate  batch_size  epochs  train_time_s  accuracy  precision  \\\n",
       "0        0.00002          16       3    331.864919  0.709184   0.616901   \n",
       "1        0.00003          16       3    268.090776  0.705357   0.609290   \n",
       "2        0.00004          16       3    294.971504  0.713010   0.617486   \n",
       "3        0.00004           8       3    324.780093  0.683673   0.623529   \n",
       "4        0.00004          32       3    263.185377  0.724490   0.632312   \n",
       "\n",
       "     recall        f1  f1_macro   roc_auc         confusion_matrix  \\\n",
       "0  0.704180  0.657658  0.702443  0.784539  [[337, 136], [92, 219]]   \n",
       "1  0.717042  0.658789  0.699765  0.774824  [[330, 143], [88, 223]]   \n",
       "2  0.726688  0.667651  0.707563  0.781310  [[333, 140], [85, 226]]   \n",
       "3  0.511254  0.561837  0.657166  0.720060  [[377, 96], [152, 159]]   \n",
       "4  0.729904  0.677612  0.718539  0.803947  [[341, 132], [84, 227]]   \n",
       "\n",
       "                                         error_cases  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  \n",
       "3                                                ...  \n",
       "4                                                ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roberta_results = pd.DataFrame(roberta_results)\n",
    "df_roberta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training roberta-base | full | lr=4e-05 | batch_size=32 | epochs=4\n",
      "Trainable params: 124,647,170/124,647,170\n",
      "{'eval_loss': 0.5962445735931396, 'eval_accuracy': 0.6984293193717277, 'eval_precision': 0.7028985507246377, 'eval_recall': 0.6381578947368421, 'eval_f1': 0.6689655172413793, 'eval_f1_macro': 0.6960212201591511, 'eval_roc_auc': 0.7657551945997257, 'eval_runtime': 5.6418, 'eval_samples_per_second': 169.273, 'eval_steps_per_second': 5.317, 'epoch': 1.0}\n",
      "{'loss': 0.6524, 'grad_norm': 17.647567749023438, 'learning_rate': 3.96e-05, 'epoch': 1.1111111111111112}\n",
      "{'eval_loss': 0.600162923336029, 'eval_accuracy': 0.680628272251309, 'eval_precision': 0.6095791001451378, 'eval_recall': 0.9210526315789473, 'eval_f1': 0.7336244541484717, 'eval_f1_macro': 0.6674658218454776, 'eval_roc_auc': 0.8330740428224871, 'eval_runtime': 5.6638, 'eval_samples_per_second': 168.616, 'eval_steps_per_second': 5.297, 'epoch': 2.0}\n",
      "{'loss': 0.4909, 'grad_norm': 11.633252143859863, 'learning_rate': 2.476923076923077e-05, 'epoch': 2.2222222222222223}\n",
      "{'eval_loss': 0.547239363193512, 'eval_accuracy': 0.7738219895287958, 'eval_precision': 0.7575107296137339, 'eval_recall': 0.7741228070175439, 'eval_f1': 0.7657266811279827, 'eval_f1_macro': 0.7735515996733031, 'eval_roc_auc': 0.8467812818619695, 'eval_runtime': 5.6695, 'eval_samples_per_second': 168.446, 'eval_steps_per_second': 5.292, 'epoch': 3.0}\n",
      "{'loss': 0.299, 'grad_norm': 13.956273078918457, 'learning_rate': 9.384615384615385e-06, 'epoch': 3.3333333333333335}\n",
      "{'eval_loss': 0.6901915073394775, 'eval_accuracy': 0.7643979057591623, 'eval_precision': 0.7242718446601941, 'eval_recall': 0.8179824561403509, 'eval_f1': 0.768280123583934, 'eval_f1_macro': 0.7643317550827018, 'eval_roc_auc': 0.8533074921773371, 'eval_runtime': 5.6688, 'eval_samples_per_second': 168.466, 'eval_steps_per_second': 5.292, 'epoch': 4.0}\n",
      "{'train_runtime': 418.4546, 'train_samples_per_second': 27.358, 'train_steps_per_second': 0.86, 'train_loss': 0.4284095472759671, 'epoch': 4.0}\n",
      "{'eval_loss': 0.6687981486320496, 'eval_accuracy': 0.7066326530612245, 'eval_precision': 0.6345514950166113, 'eval_recall': 0.6141479099678456, 'eval_f1': 0.6241830065359477, 'eval_f1_macro': 0.6917986162386851, 'eval_roc_auc': 0.7761024588213701, 'eval_runtime': 4.6251, 'eval_samples_per_second': 169.511, 'eval_steps_per_second': 5.405, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "# 3. Epochs (use best LR & batch size)\n",
    "best_bs_full = 32\n",
    "result = run_experiment(\n",
    "        model_name=\"roberta-base\",\n",
    "        strategy=\"full\",\n",
    "        learning_rate=best_lr_full,\n",
    "        batch_size=best_bs_full,\n",
    "        # Just need for epoch 4\n",
    "        epochs=4,\n",
    "        lora_config=None)\n",
    "\n",
    "roberta_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_roberta_results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"mode\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\",\n          \"RobertaForSequenceClassification(\\n  (roberta): RobertaModel(\\n    (embeddings): RobertaEmbeddings(\\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\\n      (token_type_embeddings): Embedding(1, 768)\\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n      (dropout): Dropout(p=0.1, inplace=False)\\n    )\\n    (encoder): RobertaEncoder(\\n      (layer): ModuleList(\\n        (0-11): 12 x RobertaLayer(\\n          (attention): RobertaAttention(\\n            (self): RobertaSdpaSelfAttention(\\n              (query): Linear(in_features=768, out_features=768, bias=True)\\n              (key): Linear(in_features=768, out_features=768, bias=True)\\n              (value): Linear(in_features=768, out_features=768, bias=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n            (output): RobertaSelfOutput(\\n              (dense): Linear(in_features=768, out_features=768, bias=True)\\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n              (dropout): Dropout(p=0.1, inplace=False)\\n            )\\n          )\\n          (intermediate): RobertaIntermediate(\\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\\n            (intermediate_act_fn): GELUActivation()\\n          )\\n          (output): RobertaOutput(\\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n            (dropout): Dropout(p=0.1, inplace=False)\\n          )\\n        )\\n      )\\n    )\\n  )\\n  (classifier): RobertaClassificationHead(\\n    (dense): Linear(in_features=768, out_features=768, bias=True)\\n    (dropout): Dropout(p=0.1, inplace=False)\\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\\n  )\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenizer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\",\n          \"RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\\n\\t0: AddedToken(\\\"<s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t1: AddedToken(\\\"<pad>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t2: AddedToken(\\\"</s>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t3: AddedToken(\\\"<unk>\\\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\\n\\t50264: AddedToken(\\\"<mask>\\\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\\n}\\n)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strategy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.366600265340757e-06,\n        \"min\": 2e-05,\n        \"max\": 4e-05,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 8,\n        \"max\": 32,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.35277094966326,\n        \"min\": 263.18537735939026,\n        \"max\": 418.9403269290924,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          331.86491894721985\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013369553746281331,\n        \"min\": 0.6836734693877551,\n        \"max\": 0.7244897959183674,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7091836734693877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009730614439063718,\n        \"min\": 0.6092896174863388,\n        \"max\": 0.6345514950166113,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6169014084507042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08769945415895201,\n        \"min\": 0.5112540192926045,\n        \"max\": 0.729903536977492,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7041800643086816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.042880462268174616,\n        \"min\": 0.5618374558303887,\n        \"max\": 0.6776119402985075,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6576576576576577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021084716951100507,\n        \"min\": 0.6571662329052144,\n        \"max\": 0.7185387095701892,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7024430195161903\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028192909556030283,\n        \"min\": 0.7200600939477781,\n        \"max\": 0.8039468943529364,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.78453872456714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error_cases\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_roberta_results"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-856df1f2-2c4c-45a5-9ebf-90fb2aa651d5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>strategy</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>error_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>331.864919</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>0.784539</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>268.090776</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.609290</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.774824</td>\n",
       "      <td>[[330, 143], [88, 223]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>294.971504</td>\n",
       "      <td>0.713010</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.667651</td>\n",
       "      <td>0.707563</td>\n",
       "      <td>0.781310</td>\n",
       "      <td>[[333, 140], [85, 226]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>324.780093</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.511254</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.657166</td>\n",
       "      <td>0.720060</td>\n",
       "      <td>[[377, 96], [152, 159]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>263.185377</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.677612</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>[[341, 132], [84, 227]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RobertaForSequenceClassification(\\n  (roberta)...</td>\n",
       "      <td>RobertaTokenizerFast(name_or_path='roberta-bas...</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>418.940327</td>\n",
       "      <td>0.706633</td>\n",
       "      <td>0.634551</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.624183</td>\n",
       "      <td>0.691799</td>\n",
       "      <td>0.776102</td>\n",
       "      <td>[[363, 110], [120, 191]]</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-856df1f2-2c4c-45a5-9ebf-90fb2aa651d5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-856df1f2-2c4c-45a5-9ebf-90fb2aa651d5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-856df1f2-2c4c-45a5-9ebf-90fb2aa651d5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-433f589f-b07a-4c10-ac75-b99437f32075\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-433f589f-b07a-4c10-ac75-b99437f32075')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-433f589f-b07a-4c10-ac75-b99437f32075 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_34ed28bd-2a0f-40a5-a0fe-0b3d0b498fc6\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_roberta_results')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_34ed28bd-2a0f-40a5-a0fe-0b3d0b498fc6 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_roberta_results');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                mode  \\\n",
       "0  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "1  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "2  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "3  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "4  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "5  RobertaForSequenceClassification(\\n  (roberta)...   \n",
       "\n",
       "                                           tokenizer         model strategy  \\\n",
       "0  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "1  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "2  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "3  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "4  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "5  RobertaTokenizerFast(name_or_path='roberta-bas...  roberta-base     full   \n",
       "\n",
       "   learning_rate  batch_size  epochs  train_time_s  accuracy  precision  \\\n",
       "0        0.00002          16       3    331.864919  0.709184   0.616901   \n",
       "1        0.00003          16       3    268.090776  0.705357   0.609290   \n",
       "2        0.00004          16       3    294.971504  0.713010   0.617486   \n",
       "3        0.00004           8       3    324.780093  0.683673   0.623529   \n",
       "4        0.00004          32       3    263.185377  0.724490   0.632312   \n",
       "5        0.00004          32       4    418.940327  0.706633   0.634551   \n",
       "\n",
       "     recall        f1  f1_macro   roc_auc          confusion_matrix  \\\n",
       "0  0.704180  0.657658  0.702443  0.784539   [[337, 136], [92, 219]]   \n",
       "1  0.717042  0.658789  0.699765  0.774824   [[330, 143], [88, 223]]   \n",
       "2  0.726688  0.667651  0.707563  0.781310   [[333, 140], [85, 226]]   \n",
       "3  0.511254  0.561837  0.657166  0.720060   [[377, 96], [152, 159]]   \n",
       "4  0.729904  0.677612  0.718539  0.803947   [[341, 132], [84, 227]]   \n",
       "5  0.614148  0.624183  0.691799  0.776102  [[363, 110], [120, 191]]   \n",
       "\n",
       "                                         error_cases  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  \n",
       "3                                                ...  \n",
       "4                                                ...  \n",
       "5                                                ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roberta_results = pd.DataFrame(roberta_results)\n",
    "df_roberta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_roberta_summary\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.366600265340757e-06,\n        \"min\": 2e-05,\n        \"max\": 4e-05,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4e-05,\n          2e-05,\n          3e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 8,\n        \"max\": 32,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          32,\n          16,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013369553746281333,\n        \"min\": 0.6836734693877551,\n        \"max\": 0.7244897959183674,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7244897959183674,\n          0.7130102040816326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009730614439063718,\n        \"min\": 0.6092896174863388,\n        \"max\": 0.6345514950166113,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6323119777158774,\n          0.6174863387978142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08769945415895201,\n        \"min\": 0.5112540192926045,\n        \"max\": 0.729903536977492,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.729903536977492,\n          0.7266881028938906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021084716951100507,\n        \"min\": 0.6571662329052144,\n        \"max\": 0.7185387095701892,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7185387095701892,\n          0.7075630753621891\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57.35277094966325,\n        \"min\": 263.18537735939026,\n        \"max\": 418.9403269290924,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          263.18537735939026,\n          294.9715037345886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confusion_matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_roberta_summary"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d20f6f5f-aa62-4f58-8f6a-8f19629410af\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>263.185377</td>\n",
       "      <td>[[341, 132], [84, 227]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.713010</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.707563</td>\n",
       "      <td>294.971504</td>\n",
       "      <td>[[333, 140], [85, 226]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709184</td>\n",
       "      <td>0.616901</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.702443</td>\n",
       "      <td>331.864919</td>\n",
       "      <td>[[337, 136], [92, 219]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.609290</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>268.090776</td>\n",
       "      <td>[[330, 143], [88, 223]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.706633</td>\n",
       "      <td>0.634551</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.691799</td>\n",
       "      <td>418.940327</td>\n",
       "      <td>[[363, 110], [120, 191]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00004</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.511254</td>\n",
       "      <td>0.657166</td>\n",
       "      <td>324.780093</td>\n",
       "      <td>[[377, 96], [152, 159]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d20f6f5f-aa62-4f58-8f6a-8f19629410af')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d20f6f5f-aa62-4f58-8f6a-8f19629410af button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d20f6f5f-aa62-4f58-8f6a-8f19629410af');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-f7b12c0e-4bab-4c24-825f-13f6bc2230fa\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7b12c0e-4bab-4c24-825f-13f6bc2230fa')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-f7b12c0e-4bab-4c24-825f-13f6bc2230fa button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_3d0d04de-2eeb-47b4-a0ef-5644288fd686\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_roberta_summary')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_3d0d04de-2eeb-47b4-a0ef-5644288fd686 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_roberta_summary');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   learning_rate  batch_size  epochs  accuracy  precision    recall  f1_macro  \\\n",
       "0        0.00004          32       3  0.724490   0.632312  0.729904  0.718539   \n",
       "1        0.00004          16       3  0.713010   0.617486  0.726688  0.707563   \n",
       "2        0.00002          16       3  0.709184   0.616901  0.704180  0.702443   \n",
       "3        0.00003          16       3  0.705357   0.609290  0.717042  0.699765   \n",
       "4        0.00004          32       4  0.706633   0.634551  0.614148  0.691799   \n",
       "5        0.00004           8       3  0.683673   0.623529  0.511254  0.657166   \n",
       "\n",
       "   train_time_s          confusion_matrix  \n",
       "0    263.185377   [[341, 132], [84, 227]]  \n",
       "1    294.971504   [[333, 140], [85, 226]]  \n",
       "2    331.864919   [[337, 136], [92, 219]]  \n",
       "3    268.090776   [[330, 143], [88, 223]]  \n",
       "4    418.940327  [[363, 110], [120, 191]]  \n",
       "5    324.780093   [[377, 96], [152, 159]]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roberta_summary = df_roberta_results[[\"learning_rate\", \"batch_size\", \"epochs\", \"accuracy\", \"precision\", \"recall\", \"f1_macro\",\n",
    "                                         \"train_time_s\", \"confusion_matrix\"]].sort_values(by=\"f1_macro\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_roberta_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02VBxY8pv1Qr"
   },
   "source": [
    "## 5. Run the best model and retrieve error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training roberta-base | full | lr=0.0004 | batch_size=32 | epochs=3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2c0b33d9044aaaa124f06f6871153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148e150548724b73bdabcc9dd916d71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afd685694054757b7dfeb78d92161d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 124,647,170/124,647,170\n",
      "{'eval_loss': 0.6924459338188171, 'eval_accuracy': 0.5225130890052356, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_f1_macro': 0.343191196698762, 'eval_roc_auc': 0.45707863094610274, 'eval_runtime': 12.1126, 'eval_samples_per_second': 78.844, 'eval_steps_per_second': 2.477, 'epoch': 1.0}\n",
      "{'loss': 0.7022, 'grad_norm': 1.8877636194229126, 'learning_rate': 0.00039600000000000003, 'epoch': 1.1111111111111112}\n",
      "{'eval_loss': 0.6923642754554749, 'eval_accuracy': 0.5225130890052356, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_f1_macro': 0.343191196698762, 'eval_roc_auc': 0.4665559188552544, 'eval_runtime': 12.1313, 'eval_samples_per_second': 78.722, 'eval_steps_per_second': 2.473, 'epoch': 2.0}\n",
      "{'loss': 0.7074, 'grad_norm': 0.39850330352783203, 'learning_rate': 0.00016705882352941178, 'epoch': 2.2222222222222223}\n",
      "{'eval_loss': 0.6921640634536743, 'eval_accuracy': 0.5225130890052356, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_f1_macro': 0.343191196698762, 'eval_roc_auc': 0.5343713743276025, 'eval_runtime': 12.119, 'eval_samples_per_second': 78.802, 'eval_steps_per_second': 2.475, 'epoch': 3.0}\n",
      "{'train_runtime': 477.3593, 'train_samples_per_second': 17.986, 'train_steps_per_second': 0.566, 'train_loss': 0.7030041729962384, 'epoch': 3.0}\n",
      "{'eval_loss': 0.6892092823982239, 'eval_accuracy': 0.6033163265306123, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_f1_macro': 0.37629276054097055, 'eval_roc_auc': 0.5018966302522723, 'eval_runtime': 9.8505, 'eval_samples_per_second': 79.59, 'eval_steps_per_second': 2.538, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Run the best model again\n",
    "\n",
    "best_model = run_experiment(\n",
    "        model_name=\"roberta-base\",\n",
    "        strategy=\"full\",\n",
    "        learning_rate=4e-4,\n",
    "        batch_size=32,\n",
    "        epochs=3,\n",
    "        lora_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b83e6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b83e6_row0_col0, #T_b83e6_row0_col1, #T_b83e6_row0_col2, #T_b83e6_row1_col0, #T_b83e6_row1_col1, #T_b83e6_row1_col2, #T_b83e6_row2_col0, #T_b83e6_row2_col1, #T_b83e6_row2_col2, #T_b83e6_row3_col0, #T_b83e6_row3_col1, #T_b83e6_row3_col2, #T_b83e6_row4_col0, #T_b83e6_row4_col1, #T_b83e6_row4_col2, #T_b83e6_row5_col0, #T_b83e6_row5_col1, #T_b83e6_row5_col2, #T_b83e6_row6_col0, #T_b83e6_row6_col1, #T_b83e6_row6_col2, #T_b83e6_row7_col0, #T_b83e6_row7_col1, #T_b83e6_row7_col2, #T_b83e6_row8_col0, #T_b83e6_row8_col1, #T_b83e6_row8_col2, #T_b83e6_row9_col0, #T_b83e6_row9_col1, #T_b83e6_row9_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b83e6\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b83e6_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_b83e6_level0_col1\" class=\"col_heading level0 col1\" >true_label</th>\n",
       "      <th id=\"T_b83e6_level0_col2\" class=\"col_heading level0 col2\" >pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_b83e6_row0_col0\" class=\"data row0 col0\" >Just walked in to #Starbucks and asked for a \"tall blonde\" Hahahaha #irony</td>\n",
       "      <td id=\"T_b83e6_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_b83e6_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_b83e6_row1_col0\" class=\"data row1 col0\" >So much #sarcasm at work mate 10/10 #boring 100% #dead mate full on #shit absolutely #sleeping mate can't handle the #sarcasm</td>\n",
       "      <td id=\"T_b83e6_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "      <td id=\"T_b83e6_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row2\" class=\"row_heading level0 row2\" >5</th>\n",
       "      <td id=\"T_b83e6_row2_col0\" class=\"data row2 col0\" >Corny jokes are my absolute favorite</td>\n",
       "      <td id=\"T_b83e6_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row3\" class=\"row_heading level0 row3\" >8</th>\n",
       "      <td id=\"T_b83e6_row3_col0\" class=\"data row3 col0\" >if Christian expects Fifa to sleep in my bed with me tonight, he's wrong </td>\n",
       "      <td id=\"T_b83e6_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row4\" class=\"row_heading level0 row4\" >10</th>\n",
       "      <td id=\"T_b83e6_row4_col0\" class=\"data row4 col0\" >Most important thing I've learned in school</td>\n",
       "      <td id=\"T_b83e6_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row5\" class=\"row_heading level0 row5\" >12</th>\n",
       "      <td id=\"T_b83e6_row5_col0\" class=\"data row5 col0\" >I love context and large ensemble Fridays!!!!! Der my most favourite #Sarcasm #GetTheFuckOut</td>\n",
       "      <td id=\"T_b83e6_row5_col1\" class=\"data row5 col1\" >1</td>\n",
       "      <td id=\"T_b83e6_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row6\" class=\"row_heading level0 row6\" >15</th>\n",
       "      <td id=\"T_b83e6_row6_col0\" class=\"data row6 col0\" >Always classy, never trashy and just a little sassy.</td>\n",
       "      <td id=\"T_b83e6_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row6_col2\" class=\"data row6 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row7\" class=\"row_heading level0 row7\" >16</th>\n",
       "      <td id=\"T_b83e6_row7_col0\" class=\"data row7 col0\" >you believe you can say something, provide no proof and its a fact, WRONG @user @user</td>\n",
       "      <td id=\"T_b83e6_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row7_col2\" class=\"data row7 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row8\" class=\"row_heading level0 row8\" >18</th>\n",
       "      <td id=\"T_b83e6_row8_col0\" class=\"data row8 col0\" >@user Re: Jamie Grace has Tourette's? Thanks for sharing. I'm about to research her & post my tribute to this Young lady Gospel singer</td>\n",
       "      <td id=\"T_b83e6_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_b83e6_row8_col2\" class=\"data row8 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b83e6_level0_row9\" class=\"row_heading level0 row9\" >19</th>\n",
       "      <td id=\"T_b83e6_row9_col0\" class=\"data row9 col0\" >@user Guess they didn't get the memo reg non-nuclear Baltic sea #sarcasm</td>\n",
       "      <td id=\"T_b83e6_row9_col1\" class=\"data row9 col1\" >1</td>\n",
       "      <td id=\"T_b83e6_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7b501c88bfb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the error cases from the best model run\n",
    "\n",
    "best_model_results = []\n",
    "best_model_results.append(best_model)\n",
    "best_model_df = pd.DataFrame(best_model_results)\n",
    "error_cases = best_model_df.loc[0, 'error_cases']\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "error_cases.style.set_properties(**{'text-align': 'left'}).set_table_styles([{'selector': 'th', 'props': [('text-align', 'left')]}])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
